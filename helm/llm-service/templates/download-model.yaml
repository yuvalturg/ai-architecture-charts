{{- $root := . }}
{{- $models := include "llm-service.mergeModels" . | fromJson }}
{{- $deployModels := include "llm-service.deployModels" $models | fromJson }}
{{- range $key, $model := $deployModels }}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: download-{{ $key }}
spec:
  template:
    spec:
      containers:
        - command:
          - python3
          - /vllm-utils/vllm-model-download.py
          - --model
          - {{ $model.id }}
          - --download-dir
          - /model
          envFrom:
            - secretRef:
                name: huggingface-secret
          env:
            - name: HOME
              value: /model
          {{- if eq $root.Values.device "gpu" }}
          image: {{ $root.Values.servingRuntime.gpuImage }}
          {{- else }}
          image: {{ $root.Values.servingRuntime.cpuImage }}
          {{- end }}
          imagePullPolicy: IfNotPresent
          name: download-model
          volumeMounts:
            - name: model
              mountPath: /model
            - name: vllm-utils
              mountPath: /vllm-utils
      volumes:
        - name: model
          persistentVolumeClaim:
            claimName: {{ $key }}
        - name: vllm-utils
          configMap:
            name: vllm-utils
      restartPolicy: OnFailure
{{- end }}
